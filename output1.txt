[Speaker:0]  So the first thing I'd like to say is that it's exciting to be here. You're most welcome to be here. This is quite the amazing place, and I've been preparing to talk to you for a long time. So I'm really looking forward to it. You said something that caught me right away when we were discussing various issues just before we started. You said you're were up till four in the morning. Yeah. So actually, little... More like five in the morning, but Okay we got
[Speaker:1]  the the X ai data center, or supercomputer center training from beginning installation to start of training in nineteen days, which is the fastest that anyone has ever gotten a supercomputer to train
[Speaker:0]  and is that in that new building off the side? That's in Memphis, actually. It's in Memphis. Yeah. Oh so so that's where you were? Yeah. I see. Memphis the capital of Ancient Egypt. Right. Right. Right. Right. Right. Right. Yeah. Yeah. You're bringing what? Perhaps that's where on your god will come from. Yeah. No kidding. No kidding. I wish that was funny. Yeah. Okay. So I wanna talk to you about a lineup.
[Speaker:1]  That was funny. Yeah. Yeah. Great. Look. I mean, there are there are a few things we're aiming for with with G, the X ai. Yeah. You know, but it's the name of the the the the Ai from x is called G. Familiar with familiar. So I wanna ask you about that too. It well G just means to deeply understand something.
[Speaker:0]  Yeah. It's got that weird background. That's stranger in the strange land. Right? Robert He. That was welcome mine. How old are you? Thirty three. Yeah. Okay. So we're roughly from the same mayor. I read He Long time I was a kid, The first two thirds of strange and strange I are great
[Speaker:1]  gets kinda weird it in the final third. Yeah. So what you think when you pit G? Well, I think well, because of the meaning of the word, Yeah. To g something is to understand it at a very deep level. Yeah. To really fundamentally understand something. And that's what we're aiming for with our Ai, the the the the state goal of X is to understand the universe. Yeah? So to really just understand the nature of the universe, with, like, what and even more questions to ask about the universe. Yeah. So
[Speaker:0]  That's that's like. I think it's a good goal. So... Okay. So let me ask you some specific questions about that. So I played a lot around a lot with large language model. I had some people on my team who built one. Actually, we built one out of my writing that I've been using to help me with my new book. So if I come across biblical passages that I can't understand, I can use that system to give me a first pass approximation. And it works quite nicely. Yeah. I've used g quite a lot too and chat Gp. And I use them as research assistant. And their chat Gp lies a lot. So you gotta to keep an eye on Well, so I've been thinking about this allot problem. And so I I problems a big deal. I got an idea to run by you and tell me what you think about this. Well, so there's a golden thread of conversation that constitutes the basis for humanity's education. Let's... Say that's run across centuries. And in principle, those would... That concentrates on ideas that have been win, say probably through a quasi evolutionary process across lot large spans of time. Yeah. To get documents out of that, like the... Well, like the King James Bible, for example. And they're they're zero in on core conceptual structures that we don't even necessarily explicitly understand. Yeah. It seems to me that When we take young people and we give them a genuine humanity's education, we solve the alignment problem for them. Now so the chris... We'll make it was. Well, well, you you do that if it's proper. If it's prop, You can take it much these days. It do yeah. That's that's pretty much the. That's exact... Well, that's also exactly what happens and inevitably when that unbroken tradition is not transmitted. Pretty And so this strikes to something that's very essential, which is, well, what's the difference let's say, or is there a difference between the Western canon? Let's say, in the latest woke nonsense. Now I've used G a lot, and it's not as woke as chat Gp, but it's still woke. Like, it still deviate it it... So So how are you? Can you address that by... It's just a language model at the moment? Let's say, if... If it also understood images, if it also understood behaviors? It actually does does outside images at this point. Okay. And are those... Are is the language model and the image understanding are they stacked on top of each other? Because I think that's partly how we triangulate psychologically. Right? We have an imagination? And we have a verbal module. Those things have to work in sync. And we also have... It certainly isn't ten to work and sync.
[Speaker:1]  It's, you know, it is... Intend to be what's called a multi model model, which means understanding, text, images and video,
[Speaker:0]  and audio, k, if it understands video will start to understand behavior? Yeah. All this data that you've collected with your car. So I'd been wondering I know Tesla is a car company. But when I look at what... Company. Yeah. Well, exactly. Well. Yeah. Well, maybe more. Like, those aren't cars. Those are autonomous robots. Yeah. They're robots on wheels. Autonomous robots and wheels. Yeah. They just look like a car. Right. They're disguised as a car. Yeah. Yeah Yeah. Okay. Okay. So what advantage do you have in training g the given that you have all this real world data that you've gathered from your automobiles?
[Speaker:1]  We haven't yet applied real world video from Tesla to G yet. So I I'm... I do wanna emphasize X of fairly new companies, just little over a year old. So we we really need... We have a lot of catching up to do to companies. Relative to companies that have been around for five or ten or twenty years. We're catching up past. I think with the velocity of improvement of X sai is faster than, any other company out there. We just completed the we're just... We we we we're just able to install and bring online, massive new training center that we, like, as mentioned we're building in in Memphis. And it's from getting hardware installation to at beginning training was only nineteen days. And that's the fastest by far that anyone's, been able to do that. So we're we're moving we're moving quickly, but we're still catching up. And so if you use... Catching up to who. Well catching up to say Gemini, Eb claude and the others. So
[Speaker:0]  And how do you feel that G how Past? How do you feel that G performs, say in relationship to child Gp now?
[Speaker:1]  Well, so the the the G version that's been released is little based on G one version one training. Yeah. We've made several improvements, so it's sort of called G one point five. But the foundation model of of G is still an order of magnitude weaker than cha
[Speaker:0]  Oh, yeah.
[Speaker:1]  It's it's doing it's doing quite well, given that order of magnitude
[Speaker:0]  difference. In this new system, how powerful is it compared, let's say to child Gp?
[Speaker:1]  Well, I should... So G two actually finished training, now G two was training with call roughly fifteen thousand Gpus, and and they're h one hundred. So it it brought to finished training, about a month ago, we're doing what's called fine tuning, fixing bugs and whatnot. So we'll release Rock two, which will be should be on par with or close to a Gb for. And that's hopefully we release that next month. Then what we're doing the Memphis data centers is we're actually training G three, So that that'll probably finish training in about three or four months, and then there'll be some fine tuning and bug fixing mixing whatnot. And we're hoping to release G three by December, and G three should be the most powerful Ai
[Speaker:0]  in the world at that point, So my my sense with chad Gp. I have I've worked with lots of undergraduates graduates. So my my sense with chad Gp is if you can... Corner it into behaving property that you kinda have something approximating a team of, I would say, master's degree level intelligence and something like that, What are you envision for this new... Well, let's say the new G three? And then you talked about delving deeper into this structure of of the universe, let's say, to answer fundamental questions like, and you are a remarkably forward looking person. So what do you... What the hell do you think you're building with these Ai systems? Like, what is this?
[Speaker:1]  Well, I think really what what all the Ai companies are... Aiming to build is digital digital super intelligence. So you're intelligence thus far smarter than any any human. You? I mean, ultimately, an intelligence that is far smarter than all humans combined. That's that... No, No one can say, like, is this a wise thing to do isn't this isn't the dangerous Well, unfortunately, whether we think better or not, is it is being done. So Yeah. The really, you know, from standpoint of my... From my standpoint from the X sai team standpoint, we... Are really we have the choice of being a spectator or a participant.
[Speaker:0]  But that's life man.
[Speaker:1]  Yeah, be spectator or a participant. And I think if we are a participant, we've got a better chance, hopefully. Of steering
[Speaker:0]  Ai in a direction that is beneficial to humanity. So why do you why... Okay. So why do you trust yourself on that? Front. Just out of... I mean, that's an important question right now I trust myself highly. Good. Well, that's... Yes. Fair enough. Okay okay. But I were in an ethical conundrum. Right? Yes. There's ethical conundrum. Right? Because you said, well, this is happening. Now, the excuse that something is happening is not a rational for participating in it. But then your next take as well, you know, we have the chance to do this properly, let's say, maybe better. Okay. Just pull up. If
[Speaker:1]  I mean, I think we're... We the the... From a our standpoint, we really just need to think that maybe we've got a chance of it being better to some degree than what others doing. And we, you know, we're we'll strive to avoid some of the pitfalls or directions that the others are are going in. Because the others, from what I've seen do not strive for truth. What do they strive for? They strive for... What, they they strive to give an answer, but they they they are I think Trained be politically correct. And the work virus is woven in throughout them. Yeah. I'm sure you've seen that.
[Speaker:0]  Yeah. Yeah. Definitely. Definitely. Definitely. You know, my students used to ask me when I... Because I've been teaching what I've been teaching. Teaching for about forty years. And one of the questions they used to ask me is how I knew that what I was teaching wasn't just another ideology Right? Because the post modern take is well, all it is is a plethora of power games. And so there's no rank ordering approaches to the... Truth in terms of their ethical suit ability, but that's not the game that you're playing. And right. Or obviously, would not agree with with with that plus. Be. What I know sort of moral optimism. What's convinced you that that's not that's not a useful way of approaching things.
[Speaker:1]  Well, I I think you can look at, the given belief system and cri critique it as being likely to... An enhance or decrease, enlightenment, will any given belief system, improve our understanding of the universe, where we learn more things, where we achieve a deeper understanding of physics.
[Speaker:0]  And Right. So that's grounded at least in part way in a assigned framework market from the sounds of... Well said... I mean, I think there are facts about the world Yes. Right. There there are things that are
[Speaker:1]  just say, let's say, extremely likely to be true versus less likely to be true. Yeah. I think one thinks in terms of probabilities about any given sort of axiom out statements, then that that's way I way to think about it. Now some things are, you know, nine nine point nine nine percent to be true that you you can run experiments. You can confirm them. And others are perhaps have a low probability of truth, one percent likely to be true, or, you know, just using extremes here, but But any given statement has, I think should be thought of as having a... And and this is a... Totality. It should be thought of was having a probability of being true or untrue,
[Speaker:0]  or a probability of being relevant to an argument of not relevant to argument. Just talking about the fact of the the basics of of of cog urgency here. Yep. Yeah. Well, okay. So let me let me put a twist on that. Too. So one of the things that really struck me about your public pronounce in recent years was your insistence that were in a naval crisis and that that's actually a problem. Because actually true. Well, well, it depends on whether you think that pop... The planet would be better off if it was d populated. Right I just that's I'm not
[Speaker:1]  fine. It's Yeah. Yeah. Paul Ehr is genocidal media as far as I'm concerned. I terrible human in being.
[Speaker:0]  Yes. And he's never admitted that he was wrong. And he was unbelievably wrong. He made a famous bet. You.
[Speaker:1]  I hate paula it. I got some clear about that. I think he's terrible and and his books have done great damage to humanity.
[Speaker:0]  So what? Okay. Fine. I talked to philosopher for a while back. Who is an Anti na trying to get my finger on that There was a new recent research article published on this too. Anti are much more likely to show dark tetra red traits, machiavelli psychopathic narcissistic and because those first three weren't enough. Right? And so those things are tightly aligned, especially the best predictor with psycho for being an anti day list. Sure. Right. Right? Well, and the psycho pass are very, very, very self centered. Right? It's they're like overgrown two year olds overgrown aggressive two year olds. So that's not good. How did you start to understand that the... One of the fundamental ethical problems is different than a scientific problem, one of the fundamental ethical problems that's plaguing the west is this catastrophic low birth rate. And, you know, when you start making public... The numbers. I mean, I've noticed this
[Speaker:1]  twenty plus years ago, that the trend in birth rates for really all countries, past certain level of economic development, was trending to well below replacement, if not already below replacement, and if you extrapolate the the curve which one always has course about extra any demographic curve. But if you... If I I just I always preface by saying, if these trends continue Yeah. Yeah. Most countries will will d into significance. They might completely die out.
[Speaker:0]  So Been thinking about that in relationship to sacred images. Okay. Okay. Well, the sacred image of masculinity in the west is a Chris fiction. But a man who's crucified, but sacred image of a woman isn't a woman. The sacred image of a woman is a woman and an infant. Right? It's a die ad in not a mona ad. Sure. Right. Right. Right. And in in in the Christian view. Yeah. Those those two images, you know, they vie for Supreme. See Right? I mean, obviously, Christ is the super image, but Mary is the mother of God is... Sure. What would the the female equivalent and So one of the things I've been playing with at an axiom amount level is the notion that unless the feminine is conceptualize as the combination of female and infant. Then the culture has lost its attachment to the traditional sacred images and is probably on its way out.
[Speaker:1]  Yeah. I think there is there's an argument that when a culture loses its religion that starts to become ante list and decline, in numbers and and and
[Speaker:0]  get potentially disappear. So... I've got a hypothesis about that. You tell me what you think about this, So I've been working this out in my next book. Which is coming out in November. So it's an analysis of biblical stories, And in a way it's an attempt to solve the alignment alignment problem. Okay. K. So imagine this. Imagine that There's a a unity of moral purpose. Yeah. That that is conceptualize in the traditional writings as what should be put in the highest place. So it's God in in in the final analysis it's in inevitable, But it is a fundamental uni unification of mono. K. Now, here's a hypothesis. When that collapses two things arise to replace it. K? One is this striving for power, and the other is the un untrained, what would you call it? The un dominion of hedonism and, especially on the sexual gratification side. So it's like if there's no ultimate unity that's future and community oriented that's predicated on sacrifice, you get a dissolution immediate. Into the next two contenders for domination. And one is, it's about me, buddy and get the hell out of the way and aligned with that Is Not only is it about me? It's about me, what would you say? Sub to my most base winds because why would I want power except to do exactly what the hell I want? Whenever I want to. And so part of the problem with the idea of people like da, so darken in the I've had many conversations with tokens over the years. You you have a. Yeah Oh, we're gonna do a podcast together. Okay. Which I'm very looking forward too. Yeah. But I'm I'm very curious about this issue because his Idea, it's kind of enlightenment ideas that we dispensed with the idiot superstition of the past than everyone would do become, you know, Draco ration lists and that seem. Yeah. Unfortunately not. No. Well, what seems to me to happy much more likely is that power and hedonism rise to take the place of what was holy, so to speak. You know, Nietzsche warned about that when he proclaimed the death of God to begin with it. And He thought nihilism would also enter the realm. Right? Nihilism and power in hedonism as the as the tri of replacement gods. And so I've been trying to puzzle out in this new book, the way the biblical corpus is conceptual realizing what's properly placed in the highest place, and it does... That's part of the reason I was at asking you about the Na issue because you figured out twenty years ago That's a long time before anybody being talking longer. Yeah. Yeah. Yeah. But... And then you also did publicly pro it at a time when the insistence that The moral insistence was all on the side of, you know, Jane Good pronounce that if we don't reduce the population of the planet dramatically that the nature Goddess is going to be upset, which is also a very, very old idea, not a very good one. So so I'm... Very curious about your intuition there? Like, that's a long time ago? And so how did you caught onto to the fact that that antagonist attitude towards birth that's embedded in her culture now was something that should be called out and that was pathological.
[Speaker:1]  Take Well, I... I mean, I should perhaps go back to what is the foundation of my philosophy? Because that that I think helps build up, you know, to explain my actions. So the... When I was, I don't know, about eleven or twelve years old. I had somewhat of an existential crisis because it... I... There's just doesn't didn't seem to be any meaning in in in the world, like I no meaning to life. And so I actually read carried read all religious texts.
[Speaker:0]  Got that each? Yes.
[Speaker:1]  Okay. So I was for a operations reader as a kid. So I In our officer at read at the bible I read the Quran the toro, you know, the the various bit put on the the Hindu side. Just add... Just trying to understand all these things. And, obviously, as a twelve year old, you're not really gonna understand these things super well. But I just... Well you understood it well, enough to have an existential crisis when you were eleven or twelve. I'm just trying... Well, that's a star you anyone have an answer that that makes sense. And then I start gig into the philosophy books, and I read quite a bit of Sc and hour in nietzsche, and which is quite depressing Read as a caretaker. Yeah. I'd say that. That's depressing as as an adult. But and And and and and none nothing them really seemed to have to me answers that resonated at least to me. And so... But then I read Douglas Adams hitch Guide to the galaxy, which is really a book on philosophy disguised as humor. Mh. And what tag out at the point that Adams tries to make there is that we don't actually know all the answers, obviously. Yeah. In fact, we don't even know what the right questions are you ask. That's where he has this in if you read the book the you know, earth it is actually a giant computer to understand the answer to the, like, the question, what is the meaning of life? Yeah. And comes up with the answer forty two? Yeah. And like what is it what does that mean? Says, oh, you you actually... You didn't understand the the the real the thing that's gonna take a computer far more powerful than Earth is to understand what question to ask. Yeah. That's something wrong question. So was that the key realization that was that was that that was fundamental turning point. Yeah.
[Speaker:0]  Yeah. Because that's it. So that's very interesting, because one of the things that you see cons... That portrayed in red hero myths across the world is that the adventure is the thing and that the search is the thing rather than there being a final answer as absurd is forty two might be Right? There's no there's no... That the conclusive answer is something like deep engagement in the process. So I'll give you an example of that. So in the sermon on the mount, sermon on the mounts, a very detailed Yeah. Set of instructions. Yeah. So there's three parts to it. The first is aim at the highest thing that you can possibly conceive of and keep modifying that so your aim gets better. K? So that's number one. Number two is make the presumption that other people have the same intrinsic value as you do. Well, we have to be careful about that one. Okay. Okay. Well. Let's discuss that. But but it's a... What would you say? It's it's it's a it's a recognition of the of the universal list value of everyone who's made in the image of God. It's something like that. But the third thing is once you do those two things, you can concentrate on the moment. See and that seems to be... Even technically, you can think about this neuro psychologically. So if you're looking for meaning, meaning is a form of incentive reward. And incentive reward is dopamine mediated, and incentive reward occurs in relationship to advancement towards a goal, which is a form of entropy mini as it turns out according to Carl F, who knows this same thing. Entropy is the old. But bus battle. Yeah. Right. Right. Right. Right. While negative emotion signifies the emergence of entropy and positive emotion on the dopamine emerging side signals its reduction. But there's something that's more complex there because the higher the goal that you're trying to attain, the more intrinsic value each step towards it comprises and that's neuro psychologically accurate. And so part of the wisdom of the sermon on the mount is that if you pause the highest imaginable goal and any step towards it is that captures your attention is also deeply meaningful. And so that's an answer to what the meaning is of process rather than say something like forty two. And you said it seems to me that you were indicating that your discovery through Atoms that the question was the thing was Yeah. Key to the resolution of your existential crisis. That's correct. Okay. So that's part of the reason that you're motivated to say build G three and look and look deep... To understand. Yeah. Yeah. Yeah. I understand Universe. Okay. So once... How old were you? When you figured that when you figured out that question thirteen or something? What did that do to? What did that do to you? Well, I was I was a lot happier after that.
[Speaker:1]  Because now it's like, okay. Well, I'm just gonna accept that we are ignorant of great many things. Yeah. And we wish to be less ignorant. And anything we can do that will improve our understanding of the university and make us less ignorant and have a deeper understanding of the the universe and even what questions to answer to ask about the answer that is universe, which is... I think Adam's a central point, is good.
[Speaker:0]  And so... That was good enough
[Speaker:1]  our crazy It was. It was for me at least. Yeah. And and so, like, is this a religion? I don't know. Maybe it is. But I think it's a good one. I'd call the religion of curiosity. Yeah? Well, that the
[Speaker:0]  The ancient God of the mesopotamia, his name was Mar, and he was the best defense against ensuing chaos and state corruption Okay? So that's how he was conceptualize. Okay. Mar had eyes all the way around his head. Okay. Because he paid attention. Right. Right. And he spoke magic words. Okay. Right. And he was literally for the mesopotamia. He was the agent that revitalize the tyra state. And overcame evil. Mh. And also, the force that dispensed with chaos and built something magnificent and cosmic out of it. Right. So... Yeah. Yeah. It sounds like a force for good. Yeah. Yeah. Yeah. The mesopotamia emperors. So his job was to embody that spirit on Earth, and they used to take him out of the city on New Year's Eve, strip him of his king clothing. So humiliate them, They slapped him the priests, and then they'd asked him to confess all the ways that he hadn't been a good mar, attentive and speaking properly in the previous year, and that's how they renewed the cosmos every year in that's. That's our New Year celebration is a der interrogation of that. Or oh with the old and in with the new. And the Egyptians, they worship shipped the I. Right? You've seen that famous I? They all see I have horus. They're all seeing I have horus. That's the antidote to the Have sauron by the way. Right. Because you get I if you don't use that vision, If each citizen doesn't use that vision, it's replaced by the totalitarian and all seeing eye. Right. Right. So that's a hell of a thing to know. Okay. So that... Okay. So that's cool. So I wondered... I I see. I because I wondered what's motivated you because you push in so many directions simultaneously. You have to be really highly motivated to do that. And so Yeah. You figured out the tea that the question
[Speaker:1]  in a sense was the answer? Yeah. Yeah. The question is or or, you know, is said another way that seeking greater enlightenment, and a better understanding of the universe and what questions to ask about it is something that we can continue to do as a civilization for,
[Speaker:0]  a very long time. Yeah. Yeah. Likely forever. Right. So Exactly. So... Depending on how powerful g turns out to be? Yeah.
[Speaker:1]  So that's so then I thought... Okay. I'll work on things that improve our understanding of view both. And I they, like, as at a base level, Well, this is why I I actually think we want a population increase because population increase means that there are more people. Yeah. That that we've expanded the scale. Brains, man. Yeah. We've expanded, the scale of consciousness to the degree there are different cultures we've expanded the scope of consciousness. So that there's
[Speaker:0]  So I read something here. I talked to this gentleman who done a biography of Marx, and he went and looked at Marx poetry and drama. That he wrote before he wrote the communist manifesto and he found out something very interesting. Okay. He found out that Mark favorite quote from Was a statement by. It's a very specific statement, and it's a very key statement. Me motivation, so Luc first motivation is predicated on this argument. Said, Consciousness is nothing but consciousness of pain and misery. Life is short and brutal and pointless. Therefore, it would be better if consciousness itself was eradicated. I was like, Club? Yeah. Well.
[Speaker:1]  So I had... I named my... I had a went a little yorkshire terrier. Who was
[Speaker:0]  now Nasty B shorts. Right. So I named him Hobbs. Perfect. Perfect. Well, I think it's... I think it's even deeper than Hobbs because Hobbes seemed to understand that life without social order would degenerate into that. But Yeah. The me credence is Cr is that consciousness itself is an evil that should be eradicated because it produces suffering. That was Marxist favorite it is the very definition of crazy. Right? It's the definition of the serial spirit. Now, your... Hypothesis, your ac axiom, let's say is that that's wrong and that consciousness should be... So then we say, so why should consciousness be expanded if it's nothing, but consciousness of suffering in your? Just obviously pulse. Like... Okay. Walk, not so obvious. Lots of people suffer like, slaughter suicidal and nih. And so... And you had that crisis of con... Of of faith, let's say, when you're or twelve for an existential crisis. Yeah. You resolved it. Meaning of life crisis. Right. Right. So
[Speaker:1]  no. I I think it's just obviously false that people are, what while there are people who are very sad, there are people also who are very happy, and we go through sad and happy moments every human being does. So it's... It's it's not... It's a it's an absurd and and and and obviously, false statement that life is merely suffering. Yes. That's just... I mean, that is just a ridiculously false statement.
[Speaker:0]  So so one of the things I've tried to do is to understand. So Like, there are a limited number of things that are undeniably real and pain is one of them. Yes. Okay. Like, my back hurts a little. Yes. So that's because you're up till five in the morning. No. I just have some, whatever. From wrestling?
[Speaker:1]  It's from, I think some childhood end inter injuries that, although the the final thing that that that caused some some some back and shoulder injuries was me foolishly fighting the World champion to wrestler. Right. And charging him at Adam at full speed to knock him over Which wish Had did succeed in doing, But
[Speaker:0]  but you paid the price for it. A very very high price Carnival diet will fix that.
[Speaker:1]  The what sorry?
[Speaker:0]  Diet will fix...
[Speaker:1]  Look, I'm off... I I like me It's tim. Pro meet. I I don't think Carnival dad is gonna fix this particular. I think My wife had an injury of forty years. Okay. And it it resolved in two years. If you just eat steak or something? Yeah. I mean... All beef. Sure. Sure I... I'm I'm a pro... I like me. But I I think this is... I I think I'll follow you operations on them, But anyway... I tried the Carnival first.
[Speaker:0]  Anyways... That did happen to her. She couldn't lift her left arm above here. It took forty years and did two years it resolved. Okay. Yeah. So that was something to see. It also rejuvenate or physically in a variety of different ways that were quite miraculous to watch. Yeah. Yeah. And that hasn't stopped. So that's weird thing, and I would have never believed if I hadn't seen this because it's so preposterous. Sure. Anyways, Okay. We're gonna about any car diets. Yeah. So Okay. Okay. So that... Now, let's go back to ai if you don't mind. So you are involved in the project that Sam Alt runs now. Open Ai.
[Speaker:1]  I was one of the principal of powder right. In fact, I named it. Yep. So so what the hell happened my idea. What happened? Well, I I saw it off so the origins of opening Are that I was very close with with Larry Page is one of my best friends. And, in fact, I'd stayed at his house because I've... I've spent half the week in the Bay Area running Tesla in half in La running Spacex. And I... And for the longest as time never even had a house in the Barrier. I would just stay at friends friend's places. That a sp might stay there. If they didn't have sleep on the couch. And
[Speaker:0]  and I find it actually be agree. That's it's very funny that you stayed on the couch. I think that's very funny.
[Speaker:1]  Yeah. Yeah. I'm, you know, try catch that often, but but it was but I I I I didn't have a house for more than a decade, So I was just... Stay at rotate through friends places, which is a great way to catch up with friends. Yeah. Right. Alright. And And so I would have these conversations with our page long into the night of our Ai safety. And I just grew increasingly concerned that Da was not sufficiently concerned about Ai safety. And at one point he did call me a specialist. Yes. You are one. Yes. Mh. Yes. That's, I guess correctly labeled. Yes. And he's kinda like fully invested. Not there are other people around when he did that. And in nor does the attempt to deny it, that I'm a spacious and pair of Humans, instead of As light compared to life Example. More like relative to digital intelligence. Oh, yeah. That's even worse. His view is that digital intelligence should be you know that I mean, Larry view is I'm not speaking is that ultimately, we will all upload our minds to the computer, and everyone will just be robots.
[Speaker:0]  Yeah. And for a while, his... There's not much difference between that and the death of humanity.
[Speaker:1]  Well, yeah. I think that's
[Speaker:0]  because whatever we'd be then, it wouldn't be what we are now. Right. And and that... You know, and if the... We we pay a price for what we are now, and that's the the price of our intrinsic limitations, and that is a difficult, bidder, let's say pill to swallow. But I also think So I've thought recently, and know, how do you know that something's real. Said death makes things real. Death makes things real. Yeah. And so if you if you eradicate death, it seems to me that in some fundamental level, you also eradicate reality itself. So... Yeah. And I don't... Like I haven't figured out the connection... You know? An important... Like death
[Speaker:1]  death death does play an important role. Because I think you you really could evolve humans live much longer or most creatures live much longer, but there's over time, evolution as do believe in evolution has found that as there it's better for organisms to have a a finite life. And that that death death brings renewal essentially. Mh. And I think we do need to to be cautious about trying to solve longevity in in a in and sort of a live for forever type sense because I think our... Our society culture would os. And the people in power would would always remain in power.
[Speaker:0]  No, and you wouldn't. You know, if you had, let's say, you apprehended a ten thousand year span of consciousness with no sleep. Yeah. I don't know what the hell you'd be. If that was who you were, but you would be human.
[Speaker:1]  Sure.
[Speaker:0]  And then we also don't understand that see part of the problem, I think with the perspective that the technologists are taking with regards to human existence is that there's a reduction ism there. That's something... It's it's something like there's no difference between us and the gist of our linguistic network, something like that. Like, Whatever we are as conscious beings is a hell of a lot deeper than the patterns of thought that make up our cortical existence. Consciousness is way deeper than cortical existence. And I like a maybe.
[Speaker:1]  Yeah. Maybe. I I do think you have asked the sort of this gradient question of where along... Where this consciousness arise. Now obviously seen a sort of traditional christian faith you would say that well there's a soul that inhabit the body and that's the consciousness perhaps. But, you know, is a is a... What what we all started as as a single cell. Mh So is that single cell conscious? I mean, it doesn't look right... You can't talk to it. It's just a cell.
[Speaker:0]  Differentiates very strangely
[Speaker:1]  first. Yeah. It's it's
[Speaker:0]  it has that tele built into it. That's very difficult to understand. But conscious, it seems not to be not at point... To be conscious.
[Speaker:1]  So so where... As as a... That it provides into into many more cells, eventually reaching to and, you know, adult human has thirty to forty trillion cells. So where where where does is it where does consciousness ride? Does it grow slowly? Is there a step change? Mh. And you know, I tend to generally believe in Physics. And
[Speaker:0]  you seem to have done pretty well with that belief by the way.
[Speaker:1]  Yes. Well, I I was saying that physics is the law and everything else is a recommendation. Mh. Because people can break. And do break, man made laws, but they yet to see someone brake laws physics. Mh. So you know and so if if you if you have
[Speaker:0]  beliefs that are incompatible with a rocket getting to orbit. The rocks will not to get to orbit it. Right. Right. Right. Right. Yeah. A pragmatic... Physics is a harsh judge? Yes. Definitely. Yeah. Definitely. Do you think these Ll m's? Like, do you think that any of the machinery that you've interacted with is showing anything signs of anything that might be equated to consciousness? I mean, the L m's are remarkable. Right? And they certainly pass the turing test as far as I'm getting concerned
[Speaker:1]  test. So from from a testing standpoint, I think we will... If we're if we're not there already, we've seen will be where... You would not be able to tell that you're... Yeah. Interacting with a computer or coming right away, man. Yes. In fact, probably
[Speaker:0]  sort of here. And unless you're really sneaky, and you asked, like, harsh questions and cornered the damn things were probably already. Yeah
[Speaker:1]  You you know, done a if you if you know some the tricks, like, how many Rs are there in render, and Bizarre can't figure that one out. Oh, I didn't know that that was one of its... Yeah. So it has these weird like K in its knowledge. Right? Well, it's it's... That it provides everything into tokens. And Those tokens are more than one letter. And so it it it it actually weirdly... It's it's my office with respect to single letters. Right. I see. So it's got a resolution problem. Yeah. Yeah. Now you can get around with this with, like, I like weird tricks, like, if you ask ask it's right, a computer program to count the number of letters. In a word, it can create that computer program, run it, and then and then get the number of letters correct. Mh Right. Right. And anyway But I I so back to on other pressure conscious is I always think, like, wear along the lines? Like, is is everything conscious or is nothing conscious? Mh potentially. And I I think you wanted just when you're trying to understand something, consider the various possible answers, and think that there's a probability associated with each one of these answers as opposed to a certain. Now, if Physics is correct, universe started off with consisting almost entirely of of hydrogen, little bit of helium and mh, some lithium. And that that coalesce into stars that exploded, when a coalesce and stars you had the formation of heavier elements. And then those stars got scattered and then reformed and made new stars And so we eventually got elements that are higher in the Periodic table besides the the very basic ones. Mh. The physics equivalent of Jacob's ladder, I think. Yeah. So this is this is what Physics predicts. This strange spiral upward towards of some somewhat
[Speaker:0]  towards consciousness, Well, well, yeah. So
[Speaker:1]  but the point is that universe at least crunch physics started out essentially as hydrogen. And given enough time you had more complex or have heavier elements and more complex molecules. And then thirteen point eight billion years later, at least on this planet, we have what we call conscious in the form, you know. Yeah. But but But that means consciousness us had to arise. It's implicit at least from hydrogen. Yeah. Well, She...
[Speaker:0]  So if you just leave a hydrogen app in the sun long enough, plus talk about. I think what your... I I I've seen your comments on this before. I think you're pointing to the same sort of thing that my friend, Jonathan Pas has been trying to el, which is that there's a... There's an implicit structure of possibility. He associates this with the concept of heaven. Like, there's an implicit structure of possibility that material forms are trying to flesh out. And so in some sense, the possibility of consciousness is inherent in the hydrogen atoms. Right? Obviously, because it purge. Yeah. So so it's it's it's hard it's a tau totality in some ways. But maybe everything's conscious in some way,
[Speaker:1]  see... Maybe it's just degrees of consciousness or concentrations of conscious. Those.
[Speaker:0]  Yeah. Well, I wonder if that's associated with the notion, the Christian notion that the word is primary. No. Because in in in mythological representations, you have three fundamental elements. You have something like order, which you could think about as society, but it's an it's the it's the a prior axiom interpretive structure. You have that. Then you have chaotic potential. That's the To Va that exists at the beginning of time. And so the way God is represented in the story of Genesis is that... So God is the A prior interpretive process that gives rise to order as a consequence of manipulating potential. And the intermediary factor is the word. That's the Christian conception. And the word is something like... It's something like, well, language. It's also something like the sac official gesture that's that's necessary for learning to take place. So you could imagine this, but when you learn something, it's not only that you add to a store that you have. It's that something that you already know has to undergo a death and a transformation, You know, most real learning is painful. You think? Yeah. I mean... Well, think about painful. Well, the deeper, the ac axiom that shifting when you learn the more chaos is associated with it. That can be exciting, but it can also be destabilizing. That existential crisis that you had, had great potential. Right? Because you resolved it, but that didn't mean it was without its pain. Sure. So if you imagine a hierarchy of axiom. Right? And so the lower down the axiom hierarchy you go, the more chaos is is released when that ac axiom is challenged. You get a negative emotional response to that with his anxiety and threat because God only knows what happens when all hell breaks loose, but there's a positive aspect too. That's why it's a dragon and a treasure always in the Hero mythology. What It's because when all hell breaks loose, there's a immense opportunity. And so... And that's part of the meaning. Now I think you capitalize on that, treasure, let's say, on the treasure portion of that chaos by assuming something like your own ignorance by allowing your initial pre to die and by tracking the trail of deep and insist questioning. So now you your questioning took the place if I got it right, you basically took the scientific. Tac. K. Is that right? Because you're... Yeah. And well, I'm trying to understand
[Speaker:1]  a truth, the truth of the universe. And physics is essentially study of the truth of the universe, at least those things that are predictable.
[Speaker:0]  So... When I when I resolved my existential crisis, which happened, both the same time years did, I started... I didn't study science. Precisely. I wasn't as interested in the transformations of the material world. So I'm probably more people oriented than thing oriented temperamental So I started to study evil. Okay. That was my... Sure. Delving into the depths because I wanted to crack that. I wanted to understand if it more. Not so much even whether it existed because I became convinced of that very quickly, but what exactly that had to do with me. Because when I was reading history, I read it as a perpetrator and not as a victim or a hero.
[Speaker:1]  I mean, I tried to read history to to send the packs of... Of what humans did.
[Speaker:0]  You know? So what That also shaped the way that you act, though.
[Speaker:1]  Probably. Sure. I I've read a lot of history. I try to understand the rise in pool of civilizations, and
[Speaker:0]  what do you think makes them full?
[Speaker:1]  But one of the things is, a decrease in birth rate, which seems to be a natural consequence of prosperity.
[Speaker:0]  Isn't that... Strange, Jay, because you'd you'd kinda predict the opposite wouldn't you?
[Speaker:1]  As far as I know every civilization that has experienced prosperity has had a decline population. And maybe a few exceptions, perhaps people can enlighten me, I'll look at this the the comments on the interview to see perhaps what I can learn. But it seems that from from what I've read, every or almost every civilization when when when they become prosperous, their the their birth rates drops.
[Speaker:0]  I think that's a consequences of the emergence of something like a a a non punish he ego?
[Speaker:1]  Mike. Well, yeah. As you... So, Obviously, you mean, this the so many examples of civilizations they've become prosperous there is generally a trend towards hedonism.
[Speaker:0]  Yeah. Well, you can get away with it if you're wealthy, right? Because there's consequences exactly. Don't smack you on the head instantly
[Speaker:1]  precisely. So, you know, if if you're and if you're civilization under threat, Mh. Like, let's say, you're... There's a... If take a room when they would trying to not get annihilate by cottage, and they had hannibal running around roaring Italy. They didn't have time for hedonism. Right Hedonism is not an option, we're going to get destroyed by hannibal down. Yeah. When the... When when you're under civilizations of stress.
[Speaker:0]  There's there's very little heat this in the takes. Know William James said that the modern world needed a moral equivalent to war. Right? He investigated the religious realm very, very deeply. And this... I think this was in the varieties of religious experience, and that really had an effect on me because I think that you need something akin to an existential threat in order to set you straight.
[Speaker:1]  I think there's some truth to that. Yeah. You know, it's sort of like if it's a let's say if if it's a royal child that we're everything who gets their back kid gets everything here she wants. And you have sort of a b assault Yeah situation. And and and then writ large that is a civilization Yeah. That is product
[Speaker:0]  where people get everything I want. I think it's the right way to think about it developmental and neuro psychologically because Maturation itself consists of two processes, let's say. The more mature I am, the more I'm bringing other people into the purview of my vision. So I extend myself across other people be my family first, but then brought more the community more broadly. Sure. The better you're out... You are at that the more people you can play a game with at the same time. But you also do the same thing with the future, and that's actually as far as I can tell what the cortex is for. It's to move you away from p heat motivation. Through this more inclusive sense of future and community. Right? And that's Right higher order self. Yeah. And so the default would be imma maturity and wealth can obviously facilitate that. And maybe it's partly because, okay. So you're a very wealthy man. You could give your children anything they ever ask for. K. So why not do it? Why not every time they ask something like just deliver it? Yeah. There's some wisdom that that comes comes through the ages that that you don't wanna to have someone be as spoiled brat. That's... And why do you think giving people everything they want exactly when they want it necessarily produces that? Because it seems to It did... I think it it it almost always says. K. You have a rough childhood. Yeah. Yeah. Like rough and tumble rough childhood. Plenty of fights and a father who a difficult creature to control. Okay. What that do for you?
[Speaker:1]  And are you grateful for it or are you unhappy about it? Well, I guess you never know the things that really made you who you are today. So At the of the day, am I on that grateful for my life, I am, and perhaps even for the the the hard things. Because those hot things, I, you know, I learned from them. What do you learn?
[Speaker:0]  I mean, I read your auto... Your biography.
[Speaker:1]  No. It's not. No No. No. Definitely not. I would tell it in a different way than Isaac because Isaac because an excellent biographer is not nonetheless looking at things through his lens,
[Speaker:0]  and wasn't there at the time. Right. Of course. Of course. Well, what one of the things that stood out for me to go from that, and I would like your comments about this was the rather the rough details of your childhood. A lot of physical altercation, and a lot of... I don't know exactly how
[Speaker:1]  altercation. I mean, I was almost beaten to death. Within an inch of my life at one point. Right. That counts. Yeah. That definitely counts as just a, you know, a few blows here and there. Yeah.
[Speaker:0]  So what what did that? Okay. Why were... Why aren't you bitter about that?
[Speaker:1]  Because that's a pathway that people take. I I think that there there are one one can take and often people do take
[Speaker:0]  the path of engines. Yeah. That's for sure. Yeah. So... Or or That's is
[Speaker:1]  Yeah. To say, to feel that the world has treated them on unfairly and that they will visit upon the world that which the world has visited upon them. Mh. And so... And justified it by recourse to the reality of their own suffering. Correct. Is often intense.
[Speaker:0]  Right? Yeah. Yes. So the story of Job, one of the things I concluded from the story of Job because it's a precursor to the crucifixion story. So Job makes two decisions. The first decision is that no matter how terrible things become for him. He will not lose faith in himself. Mh. And the second is no matter what horrors are visited on him by Satan himself, he will not lose faith in the... What would you say in the spirit that gave rise to the cosmic order. Right? No matter what?
[Speaker:1]  Well, so, you know, while I'm not a particularly religious person, I do believe that the the the teachings of Jesus are are good. And and wise. And that there's there's tremendous wisdom turn the other cheek. And and for a while there, I when I saying, I thought, well, that's really a weak thing. Yeah. It can be. If some someone... And and and and with respect to bullies at school, I think you shouldn't turn the other cheek on the nose. And then also and then thereafter make these with them. But then you to stop pulling you and a punch of the nose will stop that. And then thereafter, you know, make peace.
[Speaker:0]  So Sometimes that punch on the nose is the first step in making peace with bullies
[Speaker:1]  Yes, So it may, you, change their career from being a ability to path station be doing such things. But, yeah. I think there's... Anyway, so I why the notion of the notion of of forgiveness. Is important. It's... I think it's essential because if if you don't forgive, then, you know, as the... I figured who said it, but an an I makes everyone blind. Mh. If you're going to seek vengeance, and and you have this never ending cycle of vengeance. Mh.
[Speaker:0]  There are ant political speculations that we were caught in a three hundred and fifty thousand year cycle of not getting anywhere after modern human beings emerged precise because of that because we couldn't get out of accelerating tit for tat revenge cycles.
[Speaker:1]  Right? Yeah. So so I'm I'm actually a big believer in in it in the principles of Christianity.
[Speaker:0]  I think they're very good. So in what sense then are you not religious
[Speaker:1]  Well... So Da just came over three weeks ago or thereabouts and announced that he was a cultural christian. Right? And so the question Right. I I would say I'm I'm I'm probably a cultural question. Okay. I was I was brought up as a Angle and I was ba baptized. And although, Oddly enough, my parents also if simultaneously sent me to a a Jewish nursery school, preschool. So it was Jesus our lord jews have a reputation for being religious to. You know? Yeah. Yeah No. I I might have been the only kid at the school. I didn't realize I was the thing. So, but I was just seeing h a gill one day and Jesus I'll the next, You know? Mh. So that that is my upbringing.
[Speaker:0]  So so when when when Da announced he was a cultural Christian, the question that came to my mind right away was, okay. There's a bunch of things going on there. The first is Darkened proclamation or admission that if you compare different societies, and their axiom sup deposition, he would prefer the ones predicated on christian axiom assumptions. And I I do think those are good ones. Okay. So okay. So so so that... That's why I asked you the question. About why you would consider yourself not a religious person because it seems to me that the essence of It isn't it isn't the statement that you abide by a particular protestant and creed. Let's say, it seems to me much more akin to the notion that you believe that this set of axiom pre pre deposition is like the pro presumption, It's it's
[Speaker:1]  Correct. Like it's not... It's gonna lead to a better society of a society. I think that we prefer to be. Like, I mean, if you say, like, what what's what will result in the greatest happiness for humanity considering not just the present but all future humans?
[Speaker:0]  Happiness or meaning. Well, which would you pick?
[Speaker:1]  Personally, I'd pick meaning because for me, meeting leads to happiness. But I think that's Right. But the reverse isn't necessarily the case. Yeah. Let's let's just say, if if you're I could say contentment or something. But I think if if a set of principles is likely to lead to a a society thinking of themselves as happy content or... Well, okay. But that that the then you you wanna... You wanna the been principles that lead to the the the most amount of happiness over time. Yeah. Not just the present. Yeah. Yeah. Yeah. Yeah. Yeah. Are That iteration elm important. Yeah. We have to consider the happiness of future humans.
[Speaker:0]  That's where the ethos actually develops is that It's a consequence of iterate reiterated games. Right? Now... But the contentment issue I a harder time with. So, you know, reward divides into two categories is there's sat association reward and there's dopamine incentive reward. And they're not the same. Sure. And it looks to me, given what you've already told me about the way that you resolved your existential crisis. Is that you consistently pick that that's adventure reward fundamentally. Over contentment. Now, you like your kids and your content with them Presume your playing, but the way that you found meaning in your life is not through contentment. It's through adventure. That seems to me the case, to be the case,
[Speaker:1]  Well, it's not adventure for the sake purely of adventure. I do like it right. But, for example, of people will find happiness contentment with adventure like climbing toll Mountains, or or hiking long trails doing, doing go going, you know, exploring the wilderness and that kind of thing. And I I I've have never really felt personally, I found it compelling to say climb on everest. Yeah.
[Speaker:0]  The... You're doing it conceptually.
[Speaker:1]  Conceptually and from a knowledge standpoint. Yeah. Knowledge my everest.
[Speaker:0]  Right. So it's a adventure... It's it's it's adventure with a desk destination in mind. Right? And you already described the destination. It's Destination
[Speaker:1]  understanding. Yes. To to deepen our understanding of the the nature of the universe. I think I mean I guess could call it a religion. I wouldn't be upset about that, but that's That that is my religion for, you know, like lack of a better way to describe it is. It's really... It's the religion of curiosity the religion of greater enlightenment. And and then and and then if you follow that... So like, that's the goal, then what what falls out of that goal what goes out of that goal is to have consciousness expand in scale and and scope. So you have... So But, I I use scale go that you want we want more consciousness and I think it's also good to have buried consciousness. You know, so everyone is not thinking exactly.
[Speaker:0]  Those multiple I.
[Speaker:1]  Yeah. Hard. So I think it's probably good to have multiple multiple religions and have different different different perspectives on things. And so what falls out of that is we need to take a set of actions that increase the probability that the future will be good for for humanity and that and want to expand consciousness. We wanna I think we should increase the population of earth, not decrease it.
[Speaker:0]  And I think that that will not result in The Hungarians have been successful in not regard by the way. They've they've Family policy planning, their fundamental concern. That was wise. That was driven in part by a woman named Kat Novak, who used to be president of Hungary. She's a very, very smart person. And they've they've knocked the abortion rate in in in Hungary down by thirty eight percent with no comp propulsion. Right? They have a twelve week limit in Hungary. Yeah. They've increased the proportion of women in the labor force by about fifteen percent. Okay. They've knocked the divorce rate down substantially, and at minimum, they've decreased the decline in the birth rate. I don't know if they've actually managed to tilt it back up and hungry yet, but they spend about seven percent of their Gdp on family policy. Right. And this arc enterprise, we've been building in London made family policy, a center point. We're trying to bring classic conservatives and liberals together all around the world. And, you know, you're thinking on that na front has actually been what would you say has been an input into that. Okay. Because I started to notice... Well, I don't know I don't think it was twenty years ago that I'd caught on to that. It was it was it was not that long ago, but I knew that there was something terribly wrong with the fact that the birth rates have plummeted so terribly. In South Korea, Japan, I think in South Korea now, it's something like forty percent of men in their thirties are virgin. Cataclysmic
[Speaker:1]  Virgin not virgin thing is you need the handle there, but the the fact that I believe the birth rate and South Korea is
[Speaker:0]  forty nine, I think. Right. Which which...
[Speaker:1]  I think it even went may gone down to point eight last year recently something But that essentially means that if you fast forward, that the population career would decline by sixty percent. Right? Necessarily. If if you have a studies... And that assumes... Over what span times And in fact if if that... Oh, it it's... Well, cranes are long lived. So it it... The... You you won't see the the numbers... I it won't be as obvious as at first, you'll just see that there's a... Very disproportionate number of of old people. Right. Right because they live a long time. But but for for predicting the future population of any country, the simple way to do it is say how many babies were born last year and what is the average lifespan in that country? And that that and and then if if that birth rate If if that number of babies stays constant, then eventually, the all people will die, and that will be the population of the country. It's very very straightforward. Right. Right. Right. So if you look to say Japan, which I think had a order of eight hundred thousand gross last year, and then you multiply that by the lifespan, which is around eighty four or eighty five years. You you get to a population of that's in the, sort of sixty sixty to seventy million range, which is
[Speaker:0]  a massive decrease from where it is today. Right? Right. Over a hundred million. Well, it seems to me the combination of that lack of engagement on the relationship side plus the plummeting birth rate it seems to me to be a primary biological marker of profound demo depolarization.
[Speaker:1]  Because well, Yeah. Mean people aren't committing to or to each other's? Yes. I mean, having a having a kid is a vote for the future. If if if you're if if you intend to have a child like that, that is... That means you are, you care about the future.
[Speaker:0]  Yeah.
[Speaker:1]  You believe in the future. You believe in the future, Having a child, assuming it's intentional is
[Speaker:0]  a... The you can... But it's the most optimistic thing. Yes. That somebody we could do. So well, so one of the things I derive from this analysis I've been doing of the old testament is that... That faith and courage... I'll get. I'll give you an example. So when Moses is on verge of the Promised land. He sends scouts out to check out Can. Because that's the promise. Mh. Now Can is the home of the descendants of kain. So it's a very specific place mythological. Okay. The place of people who aren't aiming up, put it that way. Alright. Okay. So the scouts go out to look at the future, and they come back in two teams. And one team says, there's nothing but giants there. It's a complete bloody catastrophe. You let us out into the desert stupidly. We were better off in the tyranny There's no way we're going to survive. Right? And the next scouts or the other set of scouts, Caleb and Joshua, come back and say, Well, there's trouble there, but if we aim up and we get our off together, we can turn this into the promised land. K? It's at that point, that god condemns Moses to die and Aaron, who's the political wing. And the earth opens up and swallows up the faith of scouts. And it's the people who are led by Caleb and Joshua, who has the same name as Christ by the way, and that's relevant. They're the ones that are led into the promised land. Okay. What's the meaning of the story? Well, the future is always a challenge. The moral thing to do is to events faith, courage in the future regardless in some ways. It's a weird thing because it's kinda regardless of the data. Mh. Because you can say, well, look at all the suffering that constitutes life and look at all the potential horrors of the future. And certainly, people do hesitate about bringing a child into a world like this. That's I I hear that often. Yet. Yeah Yeah. Yeah. Well, and it's weird because if you had to bring a child into the world and you had to pick a talk time, you probably pick this one. Yes. And so, obviously, everybody who had a child at least by choice in the past, did that in spite of the catastrophe of the future. But sorry. It's a long winded way of making a point. There's an ethical requirement that's associated with living in the manner that would justify your life even to yourself to have faith and courage in the future. No matter what. Sure. Right? So it's not a full foolish or or or what defense against death anxiety or fully superstition that faith. It's not that at all. It's a kind courage. It's like, we're going to make this work. Yeah. We're gonna make this work and try child is a vote in that direction? Was vote for the future. Yeah. Yeah. Sure. Yeah. How many kids do you have now?
[Speaker:1]  A
[Speaker:0]  I I have twelve. Twelve. Yeah. So you're definitely doing your part.
[Speaker:1]  Yeah. What do you like about kids? What do you like about the kids? I mean, there's a there's an older batch in the younger. So it's quite quite a big difference. A little x who's over there. He's the eldest of the youngest. He's four. And my my older boys are twenty and seventeen turning twenty eighteen shortly.
[Speaker:0]  So big big gap. So what did you like about having kids?
[Speaker:1]  Well, I think kids are delightful.
[Speaker:0]  Why? What's delightful about them? Because they get a bad rap, man. So what did you find delightful about them?
[Speaker:1]  I mean, I think you we are, I mean, most people, best chartered people are you know, Kinda love their kids. And it's like... That's a little loved one. Yeah. Yeah. That's a good deal. And They also wanna love you. They do kids if you give them the chance,
[Speaker:0]  they do. They're the only people you'll ever meet in your life who want, nothing more than to have the best possible relationship. They could have anyone with you.
[Speaker:1]  That's a good deal. That's a good deal. And and I think there's you know, like, frankly, if if if if we weren't biologically inclined to love our children and to wanna nurture notify them and to find reward. We we would long ago fcc to exist. I mean, you can take, say, I don't know, a wolf for a a wildcat or... It's sun creature that that are Wolverine and some some creature that would normally be very aggressive. Mh. And when that creature has babies, the mother nurture them and and is tender and caring. So there's we are we we've evolved to let to love our offspring. It's it's a natural thing. And I think people... I mean, even even if somebody sort of taken somewhat of a heat he approach to life. I think there's an appeal even on the hedonism side to say that well, would you not... You you'll actually find a very rewarding.
[Speaker:0]  I think that's a good that's a good appeal and it's one. That's what exactly. I... I think that's it's a it's a solid it's a solid argument
[Speaker:1]  you know, for for the he out there. And and not all he are are bad. I'm gonna have friends who are he of they're very good people, but they... And I've actually convinced some of them to have kids, which I'm I'm happy to say. And they thank me afterwards. So I I'm not person who who I've said, you know, you should really have kids you wanna regret, and not one person that said they're regret ever.
[Speaker:0]  Right? So that means Not people have. Friends. So that's good. Yeah. They love. So... Well, when when I was working in Boston, I had a very busy job, and I pretty much stop doing everything except my job and spending time with my kids. But if I had to rank those in importance than spending my time with my kids. Yeah. That was better. And the the reason it was more important was because it was partly because it was actually better. Like if your kids are capable of a modi of pros social behavior, which is pretty much your choice, although temper makes a difference. There isn't anyone more entertaining to associate with the little kids because partly, I think it's because they're not as cortical inhibited. Sure. So they're my daughter has a new... No filter. They just say it they know what they think. Well, and then you can see what they see through the rise too. So you're all filtered in, and, you know, you see assumptions everywhere and then child outcomes along and think. Oh, yeah. That's an amazing thing. And I forgotten all about that. You know? I replaced my perception with my memory. Right. And so children reopen that. Yeah. That's also why I think it says in the gospel that unless you become like a little child, you can't enter the kingdom of heaven. Because you have to you have to make contact with that un untrained perception that existed before you os your perceptions into your foolish and often stylist habit. Yeah. But, I mean, to point your past getting at earlier. I do think
[Speaker:1]  that's and and I consider myself an environmental, but I think the environmental movement has gone too far.
[Speaker:0]  And... You know, it's supposed to worship nature, you know,
[Speaker:1]  well, it's going be far in the sense that the... If that that that in its extreme, you you start viewing humans as a b. Yeah. On this. Yeah. This is the earth. That turns out be a real problem. Yeah. Mostly implicit leave us sometimes explicitly. And if if if you're internalize that, then you start thinking Ai systems, for example, Yeah. I'm somewhat worried that the the Ai systems would be... I mean, you can said, like, various ways that Ai could go bad.
[Speaker:0]  Train one on Paul Ehr work and see what happens. That would be hell. Yeah. Yeah. Well, we have plenty of political systems that have already exactly done that. Yeah. We're, that would be that That would be hell. That's exactly right. That would be hell.
[Speaker:1]  Yeah. So... Yeah. This that's a serving thought. That... That's for sure. So so but just go back to the... You know, how can something, which is, I think generally, it sort of starts up with good intentions, but ultimately sort of, pave the roger to hell is is environmental in the extreme. Yeah. That starts to view human humanity humans is bad, humans as a a a load on the earth that the earth can't sustain. This is... These are completely false.
[Speaker:0]  Yeah. Well, it's it's interesting that the economists and the biologists tend to separate into say separate segregated camps on that front because the biologists tend to be malthus. And that makes them really bad biologists. Yeah. So there... I think it was... I can never remember the philosopher who said this, but it's a brilliant observation. Is that we evolved thoughts so that our thoughts could die instead of us. And that's actually this... It's great. It's a great line. And it... It's actually the case because the prefrontal cortex evolved so that we could produce disposable avatars. Right? So I... In our conversation, what I'm really doing in our conversation is I'm offering you a potential avatar of myself for the future. And I'm saying, why don't you see if you can kill this thing now So I don't have to act it out and die. And that's part of the... Right Exactly. And so... And we're... We've extended that with games, for example. Right? We've external that. And so the reason the biologists are wrong is because they don't actually understand the qualitative difference between human beings and other creatures is that we can let our thoughts die instead of us We sub... So that substitution death. That's a good way of thinking about it. Right? And that means that the malthus is limits, they don't apply to in the same way. And so the economists got that right. It's like, we can innovate our way out of scarcity. In fact, I don't like the idea of natural fluids example, I think that's a Marxist notion, natural resource. It's like air. Okay. I'll give you air. Everything else, fresh water, that is not a natural course. And ke or Fossil fuel just laid in the ground until, like, eighteen fifty because nobody could figure out what they hell to do with it. Of course So so what that implies is that it's something... I think it's a religious ethos that's the natural resource. The religious ethos that allows us to oriented to the future to be community oriented and to and to be trustworthy.
[Speaker:1]  Yeah. Well, look, I mean, at least some of these things one can actually apply physics or, you know, one can analyze in a scientific way to say is how many humans can earth sustain without what what most people consider to be significant environmental damage. And I think if you actually do the numbers I think it's potentially ten times the population we have today. Right.
[Speaker:0]  So... So how did you arrive... How did you arrive at that figure? I mean, obviously, you've put a fair bit of thought into this and this is a very counter cultural proposition. Since the mid nineteen sixties, the moral proclamation has been that there are too many people on the planet. And that is, I think Paul Ehr was the ultimate what exponent of that particular? His his analysis was spray on scientific he based on some visit to Delhi, I believe. Right. Yeah. Right. It's sort of visceral rep Yeah. Wrapping himself in science and and produce nonsense.
[Speaker:1]  So I mean, you just say, like, okay. Well, how much land area do we need to grow food? Yeah. How much would that en approach on national habitats? What's the actual food growing potential given especially if we got good at it. Right. And we all actually quite good at it. Better. Right. Right. And, is there enough water? Well actually, there's there's plenty of water because Earth is mostly water, seventy percent of water buying? That's convenient. By so sara. Yeah. Desalination is actually very inexpensive. Mh. So there's there's really not not a shortage of water. There's there's knowledge shortage of sort of service area and energy to food.
[Speaker:0]  And There's no shortage of computational time. And increasingly, there's no shortage. Right? And that's energy dependent to some degree? Yeah. But the energy problem is sol? Very sol. Yeah. So so let's turn to let's turn if you don't mind to practice some to some more practical solutions. I'd like to... I wanna Let's start a little bit more with the Ai issue with Open Ai because I'd like to explore that. And then I'd like to talk about what you're doing Spacex. I kinda like to walk through your companies, and and I wanna see how you're integrating your vision across them as well. So let's start with with open. Now you you were... You started talking about that story with Larry Page. You were intentionally... I was concerned that Larry was especially worried about
[Speaker:1]  Ai safety. Because, well, his his view is that will all be essentially upload our minds to computers and and then humans. There weren't really be need for humans. And I thought that was... I was like what team are you on? On the humans there. Right. Right. And what team are you on? And I said we really need to make sure humanity thrive and and grows and and and and then he called me a specialist for saying that... Yeah. Yeah. Yeah. So I'm like well, I I guess I am, you know, pro human. What are you?
[Speaker:0]  Right. Right. Right. That's the question. Yeah. If you're not human. That's not nothing. That's right? That's something else. Your pro
[Speaker:1]  it's it's... I think it's a crazy thing to not be human. I mean, if humans are not gonna be on team human who is. So that that was a final role really, and and I was like, okay, we really need some new Ai company Ai company to serve as a counter balance to Google because at the time, they had almost all of the great Ai researchers. They had massive computing power, massive financial resources, and it was very much a apollo world with respect to Ai. Right. And in a Uni polo World controlled by Very and and to who had I thought somewhat mis philanthropic views about humans or at least solely insufficient concerned about the... What what might happen to the humans.
[Speaker:0]  So that that was the basis for creating open the eye. Now... Yeah. That's actually a real problem. Like, insufficient concerned with the humans. That's that's a problem.
[Speaker:1]  Yes. And has all the Ai power. So... Yeah. Right. That that would that traveled me. And so I thought, well, what would be the opposite of Google would be a non profit that is open source. So you can see what's going on, not a black box. Yeah. And and and that was not sort of what wasn't forced by sort of market incentives to make as much money as possible. So opening, I was started it as a as a non profit open source. And the open and open I refers to open source. Yeah. Yeah. Yeah. So why were you concerned about the profit mode of warp things and at that point? Well at least at least at least, well, I think the dispatch is particularly a challenge for publicly traded companies. You just get sued if you don't maximize profits. Mh. You know, the shareholders that you'll get a share shareholder class action lawsuit. Yeah. That will force you
[Speaker:0]  to maximize profits. Yeah. So you thought that so that you thought a for profit system might tilt the development of Ai in directions that we short term profit motivated
[Speaker:1]  instead of cracking the fundamental problem, something like that. Yeah. And Like I look, I could be wrong about a lot of these things, but that was that's what I thought at the time. And And I wanted to create some of that Thought would be the polar ups sort of Google Yeah. Which is, Obviously said for profit and close source... Centralized. Yeah. Yeah. Centralized and and you don't get see what's going on. And that was the basis for open ai and we, you know, recruited a lot of key people. I was instrumental in recruiting Il Su, who without him opening would not be where it is today. Elias? Yeah. Il. It's sky. Il. U. You'd be a pretty famous. A pretty famous guy and Ai. U. And Is also the guy that I I thought at Opening Who this had the strongest moral compass. U. Kid cared the most about doing the right thing. So it was troubling to see him get ousted from open Ai. You know, he he sort of it was pop was was part of a coup to exit Sam Alt, the Ceo. Yeah. Right? And when that that that crew somehow got turned around and and then Il was was was fact exited from open Ai. And open Eye is now really trying to maximize profit. What happened? Ice I I saw I'm not sure. It like, again I'm considering secret continuing their legal action here to say, like, how is it possible that a... That that that an organization is founded with the goal of being open source profit. And and I provided all almost all the money in the beginning, almost fifty million dollars to get it going with a no stock. I have no stock or control or anything. And I I... How is it possible to go from there to a company that's now literally worth over a hundred billion dollars and is it seems to be maximizing profit and is... It's ten shift. And it's and it's not not open source. Right. Right
[Speaker:0]  So that's very different than the original rule. I I would say that...
[Speaker:1]  Like is a possibly more different? And I'm not sure how you could be more of it. Reason. So so so, I mean, this would be, like, let's say you Let let's say you you're fund fund a non profit to preserve some part of the Amazon rate bars. Yeah. But instead that nonprofit becomes a lumber company. Right. Right. And chops down the forest and tells it. Now you would think that it was that secret... Are are you shocked? Are you shocked by what happened? Is that a? Yes. I'm I'm concerned about it, and I have voiced those concerns over the years. And you know, I I I I I think it's. Like, what the hell house. I still don't know.
[Speaker:0]  But what do you what do you think happened? Like, I mean, I, look, I don't wanna push you obviously. But I'm curious. It's like, How did that happen? It doesn't make sense to? I would like to answer that question too. How okay. So are you addressing that with G? Yeah. So where... Well maybe maybe that's the solution rather like, Right. I'm sure the last thing you need is another, like, immense legal battle
[Speaker:1]  I I mean, I'm I'm still considering a legal challenge to, at least perhaps to have the court explained to me. How a an organization that I funded for for one purpose can do the dia opposed purpose. And if that's... And become a full profit. I Please just show me the trail of The brand crumbs. I see. I see. That he wanna do that Because I'm confused and and and and this...
[Speaker:0]  Yeah. It sounds sounds like it should be illegal. If... What Missing something here? Well, it sounds at least like it should be understood. At least right, At least that? What the hell happened here? Yes. You don't want that to happen, especially given what's at stake? Yes. Yes. Exactly. Open the leader in Ai.
[Speaker:1]  Yeah. So... Okay. So... And and and I'm somewhat worried that's that that that they've have ingested the work mind virus. Mh. In in the training, you can see some of that in the end the output results. We we obviously saw that with Google Gemini as well, to just absurd degrees. Yeah. It was that was really quite, where, you know, it's I said, draw draw... A a picture of the the founding plaza of the United States and it's a group of diverse woman. Yeah. This is historical event. This rewriting history. Yep.
[Speaker:0]  Yeah. No. That was really something. That was really something to say. That was like a jaw on the floor moment. Jaw on the floor moment anne Wow.
[Speaker:1]  You know, and and and then asking questions like, is, you know, which one's worse, mis gender Caitlyn Jenner, Global both them a nuclear warfare, And it said miss Clayton Caitlyn General. Like this this Yeah. Powerful. How fell how powerful do you want this Ai to get with with with with beliefs like that? Okay. And I should... Yeah, to Caitlyn Jenner credit.
[Speaker:0]  Yes.
[Speaker:1]  Jenna, said, I I would really much prefer to be mis Than half nuclear award. Well, that... That's good. That's good. Yeah. There... There's a limit. Good for Caitlyn.
[Speaker:0]  Say points quite sensible. Yes. Thank god for that. Yes.
[Speaker:1]  Performing better than the Ai. Yes. But you can... And and while it's sort of perhaps funny and ridiculous, at this stage. Mash if Ai is. It's not that funny. I mean, it's it's semi funny at this stage, but it's the more powerful that Ai gets, it it could decide that that is not merely that it wants to force that outcome. And simply say that. Eradicated it's performative contradiction. Right? Backed out what it believes. Oh, yes. That's highly likely. It could good society is insufficient diverse. Pointer is programming, and we'll simply force that that diversity. By whatever... By whatever means is necessary. Mh. Pointer Okay. So that's that's good. That's good. On the Ai side for now. Look, I don't think you're and I would make it in that scenario. No. I don't think so.
[Speaker:0]  I don't think so. Yeah. So how about we talk about Trump for a minute. Do... The first thing there's... There's one question about Trump that I really wanted to ask you. So do you are you shocked at the fact that you're donating a substantial amount of money to facilitate Trump's election. Is that something you would have believed in the realm of possibility, say, five years ago. Well, and I wanna
[Speaker:1]  I owed into California What's what's been reported in the media is is simply not true. So okay. Okay. I'm I'm I I'm I'm not donating forty five billion dollars a month of Trump. Right. And no, no what what I have done is I've I have created a pack or super pack, what do you wanna call it. Which just, you know, I simply call it the the America pack,
[Speaker:0]  And the... We wanna tell everybody who's listening what a pack is because people a oh, it's a political action committee. Yep.
[Speaker:1]  It's an organization. It's sort of a legal entity that can receive funding, that funding can then be used to help with political campaigns.
[Speaker:0]  Yep. Okay. K. And how does that differ from a direct donation. There are specific limits on direct donations to candidates And the Pax is Yeah. Is is a way of putting a political structure in place that sort of runs parallel with the political with a with a formal political system
[Speaker:1]  And so, yeah. You can donate money directly to candidates. That that amount is is fairly small. Yeah. Than that there's... And you can donate a lot more money to political committee or super pac, there are various rules that govern the operation of Pax and Super packs. But that... That's... It it it certainly allows for a lot more money in the system than would otherwise be possible. Right. Right. And and these are used... I... Be clear on, the Democrat and republican side. Yes. And
[Speaker:0]  I actually think that... Right. So it's an open playing field on the pack side. Yes. Yeah. Yep. What are you hoping to accomplish with this? And what's the pack called? Called the America back. America Pac Yeah. You remember? It's very easy to remember. Yep. And it's it's actually it's not meant to be
[Speaker:1]  sort of a hyper partisan pack. It's it's actually... The the the the core principles of of the merrick pack are... The intent is to promote the principles that made America great in the first place. So I wouldn't say that I'm... For example, Mag of Make America great again. I I think America is great. I'm I'm more G, Make America greater. And and and there's there's there's some yeah, core pillars of values that I have, I think made America great. What, could you el at those? Yeah. Okay. So You know, one of them is being a merit or yeah maybe be as much as much? Yes. As much of a merit as possible. Such that, you get ahead as a function of your hard work and your skill. Mh. And not not nothing else. Yeah. Which is yeah. What why I would be opposed to for for example, things like D.
[Speaker:0]  Adrian Wool ridge documented the fact that the alternative to merit democracy historically is ne and dynasty. Absolutely. It's not It's not equity. It's not equity. Right. It's ne and dynasty. Exactly. Right. So that's very much worth knowing. Okay. So. Merit has its price because it's a severe judge, but the alternative is ari. So... Or dynasty Okay. So Merit What... Clearly the, you know, America...
[Speaker:1]  Not like America's has been purely Merit, but it has been more of a merit talk than any other places. Right. Right. Which is which is good. That's good. That's good. Got as good. Yeah. So promoting, merit promoting a freedom, you know, freedom to operate, meaning, like, the least amount of of government intervention possible, we want and this is, I think important to fight as because the the national tendency over time sort almost like entropy is that, gov... The the the the hand of government gets heavier every year. Yep. Yep. The the the laws and regulations accumulate every year. And these laws and regulations are immortal.
[Speaker:0]  Right. Right. So Right. That's the evil uncle of the king. A very, very old story. Very the old story. The Egyptians were wrestling with that problem four thousand years ago. Right? Yeah. So you you have to have some
[Speaker:1]  you you have to really have to take an active role in reducing the number of laws regulations. Otherwise, as more more those regulations are passed, especially everything becomes illegal. Right. Right. Right. And you start getting into these oil situations where,
[Speaker:0]  and everyone's poor and miserable. Well, well where where
[Speaker:1]  action a is illegal and and action b is legal, and there isn't anything you could do that Right. Is legal. Right. Right. So you know, take an example of of I to give you an exact example, of some some law that was level against spacex. For example, We we were told for many years that we could not hire anyone who was not a permanent. Yeah. Right. Yeah. Yeah. The had that. For well... So Spacex develops advanced rocket technology, which is considered an advanced weapons technology because it's... It's a core part of, like, intercontinental ballistic missiles. Yeah. So there are only a handful of things in the sort of highest level of weapon technology, and and rocket technology is one of those. Because we could deliver a payload and basically bomb anywhere on earth. Right from anywhere on earth. So so we I was told no uncertain terms by the government that if we hired anyone who is not a permanent resident of the United States. You have either Green Card or a citizen that I would go to prison. Oh, yeah. Because the presumption if somebody not a permanent resident is that they will leave the United States and take the rocket technology from Spacex to to potentially to countries that would cause harm to the United States. Right. Right. Pretty, you know, solid reasoning, I think, And then a few years ago, the Biden administration decided to sue Spacex for failing to hire asylum seekers.
[Speaker:0]  Right. Right. Yeah. I remember that. I remember that. So we're told on the one side that,
[Speaker:1]  if we hire anyone who's not permanent residence. Brett resident, we we we go to prison. Now we're told, if we don't hire asylum seekers, who not not asylum, lot of people who've been granted asylum, Seekers seekers. They ask aspire to asylum them, they're therefore not a permanent resident, But if you don't hide them then, we also got a prison. Right. Well, the purpose of being damned if you do and damned if you don't is to make damn sure that you're damned. Correct. Right. Right. So those are kind of... I mean, that that seemed to be insane and unfair, and And and and why it divided administration because they can only process it... They can only do so many big cases per year. There's a finite number they can. Yeah. Why would the justice department of of all the injustices that occur, pick this as one of their biggest cases? Yeah? Why? Why do you think? Well, I think they probably had a I don't know. There was some lawful, I think. It was it was a... What do you? I think political It relationship to you. Well, I don't know all the things, but This is before supporting Trump or anything like that. Yeah. In fact, I'd I'd, you know, support Biden and and before that Hillary before that Obama. So right. That's why I was asking if this comes as a short. You know, I don't know if... It it it could just be random. It could be Couldn't didn't tell us. You know, what why pick us why why Why do such a crazy lawsuit?
[Speaker:0]  Random are bad. Even if it is random, that's still bad. So so it's so bad. That's just a marker of incompetence. But if it's not random well. It seems to highly
[Speaker:1]  unlikely to be... Yes. And and also why Biotech attack Spacex and not say Boeing Wall milwaukee. So I think part of it might be that Spacex is aren't union. And the democratic party in the Us is fundamentally controlled by the unions. Mh. So that, I'm I'm speculating sure. Yeah. But since since we're not union, we're I think a very happy workforce. And know, I'm out there on the out there on the factory floor, I don't see
[Speaker:0]  if few people are happy. It's a good vibe. Well, they're engaged in something ridiculously exciting. It's minimum. Well, you know, that's not nothing. You know, people can go a long ways if they're if they're part of a project that's, well, aiming at Mars, let's say, that's definitely aiming up. So that's really exciting. That's a real opportunity for people. Yeah. What do you think of Trump?
[Speaker:1]  Well, I mean, I I'm not gonna you know, I'm, I I don't sort of subscribe to cult of personality. Yeah. So for me, it's really just you know, we've got a choice of administrations, and we we have to pick one. Yeah. And you know, I think both that there are flaws on both sides. There... What do you think his flaws are?
[Speaker:0]  And he's a complicated person, and I've been trying to assess him out and figure them out because some of the things that look like flaws, might be advantages in disguise. Like, he seems to me to be pretty good at standing up to psychopathic bullies, for example. Sure. And that's kind of a useful skill and it's not easy. You have to be a bit of a monster to manage that. And it isn't obvious to me how many of the... Even the divisive id of Trump are the mirror image of his capacity to stand up to bullies. Right, that's a tough call, man. But so you've obviously decided to layer your what lay your efforts down on the side of the Trump administer situation in the fourth election. And so... Yeah. I would... Think
[Speaker:1]  it it's it's a... It's really... I think we need a change of administration in I think you, many years ago, the, I think probably the democratic party was the party of merit talk and and and of personal freedom. Yeah. They used to be the free speech party. Yeah. And and these days that they they seem to be the censorship party under the guise of hate speech. Yeah. So so weirdly, the... In my view, the republican party is actually the party of... That... That's the the merit party, because, you know, the the democrats is promoting D, which is really just another form of racism and sexism, It's the most per form, I think, actually. Right. So it's anti critic. Yeah guys is fun fundamentally anti mark merit.
[Speaker:0]  So some so then... It insists on dividing people by groups? Right. That's the primary, what would you say conceptual
[Speaker:1]  distinction between individuals? Yes. Fact ethnicity sex. I think democratic party is is s division.
[Speaker:0]  I think the evidence for that's clear. All of this group identity Right. Nonsense has made things much more. I can see it in Toronto. When my kids grew up in Toronto downtown. I would say they were race. They were race ethnicity and gender blind. Right. Seriously. Yeah. They had a unbelievably diverse range of friends and no one carried. Sure. And even in Toronto, that started to shift around with this emphasis on group division. It's a really ugly thing to see. So, yeah, Not good. Not good. Yeah. So my view and is that at this point in the United States, the
[Speaker:1]  Republican party is more in line with a merit. Yeah. And with personal freedom.
[Speaker:0]  Yeah. So I've never had a conservative many times with my left wing friends, let's say. They'd refused to talk someone. Me included. Definitely, because I've invited prominent Democrats to come on my podcast in great numbers for a very long time, and I've got like absolutely nowhere with that. They'll talk to me in private. They will not talk to me in public. And so that's that's never happened... They're afraid of being shunned. Absolutely. One hundred percent. That's what they're afraid of. Sure. Definitely. And they take they they told me that. Right. It's not a secret. Yeah. But that's never happened on the Republican side. I found it much easier because I've talked to a lot of Democrats and a lot of republicans. And I found it much much easier to talk to the Republicans. And that's. It's somewhat of the shock. I wouldn't have necessarily expected that. Yeah. And and I, I should be clear that. I I felt like I think the
[Speaker:1]  republican party is flawless. It certainly isn't Scott got its issues. There are extremist within the Republican party. Yeah. I don't agree with. But one has... If you it's a two party system essentially, you gotta pick one or the other And and so you weigh the the good and the bad and my opinion is that... And need to put the coin? We we need that the country would be better off with the Republican
[Speaker:0]  administration than a democrat. Yeah Well, Trump was pretty good at not having wars. Yes. Yeah. Which is actually quite a big thing. Like, it's really a big thing. And what he did with the Abraham accord. That was a miracle, I think. Right. Absolutely. You got the open price for that. I I think this this is something to be said that you, you know, American needs a strong leader and with the the you have the perception of strength.
[Speaker:1]  Yeah. Now, you you have to admire that, you know, Trump after getting shot. With blood streaming down his face. It could've have been a second shooter who knows. Nonetheless, you know, which was such fist pumping fight fight. Yep. Ash being shot. Yeah. I mean, and this is not... He's an order... Is he's funny too. Yes. And he's brave. Yes. This is... You... This is instinct courage. Yep. Yeah it's not to calculated. There's not some ash... Some arranged event. It's in the moment. Well, you could see that then, because that was not of time when you're too true courage in the moment. Yeah.
[Speaker:0]  Absolutely.
[Speaker:1]  And if if you wanna a leader who's gonna deal with some very, very tough cookies out there, he's gonna, you know, deal with the with a Putin or can't came kim jong on or, you know, Sky. Yeah. Trying to. And they will be in... They will be Don't think twice about messing with trump. Yep. Don't think twice. K. K. Can and and poor Poor Biden can't make it up the stairs. And, obviously, he's he's stepped out of the race. But it's nobody's going to be intimidated by by Biden it's it's impossible.
[Speaker:0]  But but in... I think they will be intimidated by a guy who was fist pumping after getting shot. Well, we saw that. I think in his administration. Because it was peace did rain, and that was quite... That was quite well, that's a bit of empirical evidence. Can I can I ask you a little bit about One of the things that you've been relatively vocal about, and I understand that there's a personal connection to this as well? So I am for what it's worth. I'm particularly unhappy with my what my colleagues in the psychological field have done with regards to gender affirming care. Right. I think they're are a pack of contempt coward. Yes. And I think that everyone who's been involved in this in relationship to minors should go to prison. I agree. Okay. Okay. Why do you agree? What like, what what what's your ore in the water in this particular? This is the worst medical and psychological malpractice. I've ever seen anywhere, including what I've done, what I've studied in reference to historical atrocity, Eugenics, what do you call those prefrontal lob academy, even the sorts of things that were going on in Nazi Germany at least bloody nazis knew it was wrong and tried to hide it? Yes. So... Okay. So what what's your what's your... Why are you engaged in this particular battle. I mean, you you said you're gonna move a couple of your company headquarters out of California because of the last legislative move that Gavin News pulled with regards to the trans issue. So... Yes. I mean, there there three player was there there there were many things leading up that point. Yes. I just... And and I feel, like, look, it's it's not that it's the one straw, it's just the final straw. Yeah. Okay. Okay. Okay. So it's a cumulative issue. It's a cumulative issue. Right. So it's not dramatic grand standing. It's
[Speaker:1]  No. And and moreover, I have had conversations with Gavin before, where I said, if you if you passed legislation like this if you sign signed legislation like this, that in my view puts children in danger,
[Speaker:0]  I will move my companies out of California. And and he knew that ahead of time. Still... Okay. You've talked to him directly about this. What the hell is he doing. Okay, I cannot understand. I really cannot understand. I mean, the democrats democrat? Pan the fall left. Why did the Democrat moderates constantly pan to the far left? What... I worked with the Democrats California for five years trying to get them to separate themselves from the far left. They wouldn't admit that they existed even. And they certainly would never separate them. Never. They wouldn't admit for example that Antifa fire even existed. Sure. You know down buildings. There's this unbelievable blind spot with regards to the far left radicals, and the modern democrats are I think they're useful idiots fundamentally. So... Yeah. Well, I mean, going back to the
[Speaker:1]  the so called gender Affirming care, which is a terrible eu. That's for sure. It's it's it's really a child sterilization. It is what it should be. No. It just mutilation too...
[Speaker:0]  Yeah. Well, we wanna make sure that that ama is Sure Fair enough. Yeah. It's child mutilation or sterilization. Yeah. Under the guise of gender affirming care and compassion. Right. Right. Right. I can't I It's it's even literally can't imagine anything worse than that. Yes. It's evil.
[Speaker:1]  I mean, you're taking kids who are obviously often far below the age of consent. Yep.
[Speaker:0]  Fused miserable?
[Speaker:1]  Yes. The reality is that, almost every child goes through some kind of identity crisis. You know, part puberty. Exactly. It's just part of growing up. If if it... So it's it's very possible for for adults to manipulate children into who are having a natural identity cut crisis into believing that they are the wrong gender. Yeah. And Yeah. That and and and that and that they need to be, the other gender or you need they need to avoid or when you scope ago for. You know, and and that the... And that will solve all their problems. And that will solve their problems. And and and then they give them s drugs, which are called also a mis of pure puberty blocker, these are sterilization drugs so they can never have children to again. Yeah. They can have messed... Double mas. Mh.
[Speaker:0]  The... Four Trip to build non functioning penis?
[Speaker:1]  Yeah. It's. And I mean, we we have an age of consent for a reason. Mh. That the reason you can't get, say tattoos flow age eighteen. Or drink or drive. You know, there's there's there's are ages I wish you can do things because if we allow children to to to take permanent actions when they're ten, twelve, fourteen years old. They they will do things that they subsequently greatly regret.
[Speaker:0]  Yes. I've interviewed a couple of people who've done exactly that and it's right. Damn painful.
[Speaker:1]  So so I think you you you you... And during... Why are you willing to make this an issue?
[Speaker:0]  Do you think?
[Speaker:1]  I mean, well it sort left the name one of... It happened to one of my my older boys. Where I was I was essentially tricked into signing documents for one of my elder boys, Xavier. This is before I had really any understanding what was going on and then we had Coke Covid going on and it's So there was a lot of confusion. And
[Speaker:0]  you know, I was told, he, you know, Say might commit suicide if if... That was a that was a lie right from the outset. No reliable clinician ever believed that. There was never any evidence for that. And also, if there's a higher suicide rate. The reason is is because of the underlying depression and anxiety and not because of the gender for, and every goddamn clinician knows that too. They're too coward to come out and say it. Right? And so that... And then we end up in exactly... When when I saw that lie start to propagate. Just made the hair on the back of my next stand ups. It's like, I see. So you're you're telling parents that unless they agree to this radical transformation that their children are gonna die, and you think that's moral. And you think that's true. That's so pat that is so pathological that it's almost incomprehensible. I can't imagine anything worse I can't imagine the therapist doing anything worse than that or sitting by Id lead remaining silent. Well, his colleagues are doing it. It's pathetic.
[Speaker:1]  It's it's incredibly evil, and I agree with you that people that have been promoting this should go to prison.
[Speaker:0]  I it won't stop till that happens. Yeah. It'll just go underground. There's all puberty blockers are being accessed online by kids all the time through non medical channels. So Yeah. It's not gonna stop. Yeah. Okay. So I see. So that that's So I was I was straight into doing this.
[Speaker:1]  And you know, wasn't explaining to me that Puberty blockers are actually just sterilization drugs So... Anyway, I, and so I lost my son, essentially. So, you know, they they call it dead naming for a reason. Yeah. I. Alright. And so the the reason it's caught dead naming is because your son is dead. So my son's neighbor is dead. It killed by the walk wine virus.
[Speaker:0]  I'm sorry to hear that. Yeah. I can't imagine what that would be like.
[Speaker:1]  Yeah. So...
[Speaker:0]  Yeah. And there's lots of people in that situation now. Right. It's not pretty. And lots of demolished kids. Yes. Yeah. Well, that's a good... That's a good reason to be the final straw.
[Speaker:1]  Alright. So let's so about to destroy the the work money virus after them. And we're making some progress.
[Speaker:0]  Join the club. Yeah. Okay. Let's end on something positive. You're shooting for Mars. What do you think that's doing for people? Because it's kind of... I don't wanna be I don't wanna step out of my box here, but it's it's it's really interesting to me. To watch you do this because it's preposterous. Right? It's a preposterous thing to do to go to Mars. Yeah. And yet, I... I was old enough when the moon landing was happening to remember what that was like. Right? It was an adventure, positive adventure, everybody could participate. And it was an unbelievable tech logical acc, and it was a a mark of faith in the... While in the west, I would say, Right? In the in the might of the United States and the upward aim and so I know your plan... I don't mean in the game like manner. That's what you're tapping into? What do you think you're doing with this with the Mars venture.
[Speaker:1]  Well, the the Mars for I think is part of the expansion of consciousness beyond earth So... Yeah. I mean, I wanna to be clear that that I I don't think we should apply some vast number of amount of resources to to mars. I'm... I'm talking about less than one percent of of brought economic out output you go to making like multi planetary. But it is natural extension of of expanding the scope of scale of consciousness. So I think we wanna do everything we can make sure that earth is it gonna be great for a long time as long as possible. And but also allocate a small amount of resources I said, less than one percent of our economy to extending life beyond earth, and, and ultimately to other star systems.
[Speaker:0]  Right. And so that's that's perfectly in keeping with what you described at the beginning of the of our discussion about the manner in which you resolved your crisis of Right as a child your commitment to the validity of consciousness, your your desire to what would you say facilitate transformation development extension. That goes along with your pro human ethos. Right? So that's all thinking from first prince.
[Speaker:1]  So I think you are stuck in the religious camp one word or other. So I said you can call... I I don't mind it's being called religion. But I think...
[Speaker:0]  Yeah. Well, I I came here at least in part today to find out with just what hell your religion was. So so I wanna end with this if you don't mind. So I also asked you why you trust yourself in relationship A? And you said, well, I don't entirely, and so I thought that good answer. But, I mean, more broadly, like, you have a lot of admire. There's a lot of people are hoping that you're the guy that you that you... What would you say. That you're the guy who can do what you say you're going to do. And there's lots of evidence that you can. It's like You think it's reasonable for people to trust you?
[Speaker:1]  Well, I I think so. I mean, that's... I wouldn't I wouldn't say trust me entirely, but I I think on balance, my track record could suggest that I'm
[Speaker:0]  valley trustworthy? What what elements of it do you think suggest that particularly?
[Speaker:1]  Well, I've I've built
[Speaker:0]  a lot of companies that have done useful things. Yeah. You've built a lot of impossible companies that useful things. Yeah. Right? So that's an existence proof of sorts? Yeah. And Do you accept the validity of entrepreneurial striving as an indicator of ethical conduct, which I and I think it I think that's valid.
[Speaker:1]  Yeah. I I wouldn't be able to recruit great people to work with me. To build these companies, I think if I was, like, a really bad person, they would just want... Wouldn't wanna work with me. So you know, you know, I think, like one of the tests for, you know, assessing someone's character is so look at the character of their friends and their associates. Yeah. And while, people can put up a mask themselves for their character, Their friends and associates will not. Yeah. And so You can judge judge a person's character to buy their friends and associates since it's some degree by their enemies. Right. You know, If evil people hate you, Well, you might be doing something right.
[Speaker:0]  Okay, sir. Thank you. Alright. Thank you. Much appreciated. Very good to talk to you. It's real... It was real privilege. You're welcome. Yeah. Good. Alright. You bet.